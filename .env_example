# Sets the logger name. Only used in logging.
PIPELINE_NAME = "googlefinance-redshift"

# Sets the logging level
## Available logging levels are
## CRITICAL, ERROR, WARNING, INFO, DEBUG, NONE
PIPELINE_LOG_LEVEL = "info"

# AWS S3
## S3 URI, specifies the output file URI
AWS_S3_URI = "s3://REDACTED/REDACTED.csv"
## AWS S3 credentials
## Used to write the CSV file to S3 as well as
## read it by COPY on Readshift
AWS_ACCESS_KEY_ID = "REDACTED"
AWS_SECRET_ACCESS_KEY = "REDACTED"

# AWS Redshift
## Redshift's full DSN. Must follow pattern:
## 'postgresql://password:username@hostname:port/database'
AWS_REDSHIFT_DSN = 'postgresql://REDACTED:REDACTED@REDACTED:5439/REDACTED'
## Target table's full path. Must follow pattern:
## schema_name.table_name
AWS_REDSHIFT_TABLE = 'REDACTED'

# Google Sheet detail
## Google sheet ID
## Example:
## https://docs.google.com/spreadsheets/d/1CEopPJOmJLjbeqzTk0xo7mkMsXlLdqvcMkb6Jz1nUmI/edit#gid=0
## ID then is "1CEopPJOmJLjbeqzTk0xo7mkMsXlLdqvcMkb6Jz1nUmI"
GOOGLE_SHEET_ID = "REDACTED"
## Full path to Google service account credentials file. See README.md for more info
## If no path is specified, then the file must be in the same riectory as main.py
GOOGLE_API_CREDENTIALS_FILE = "service_account.json"
