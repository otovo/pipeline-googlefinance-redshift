# Sets the logger name. Only used in logging.
PIPELINE_NAME = "googlefinance-redshift"

# Sets the logging level
## Available logging levels are
## CRITICAL, ERROR, WARNING, INFO, DEBUG, NONE
PIPELINE_LOG_LEVEL = "info"

# AWS S3
## S3 URI, specifies the output file URI
PIPELINE_AWS_S3_URI = "s3://REDACTED/REDACTED.csv"
## AWS S3 credentials
## Used to write the CSV file to S3 as well as
## read it by COPY on Readshift
PIPELINE_AWS_ACCESS_KEY_ID = "REDACTED"
PIPELINE_AWS_SECRET_ACCESS_KEY = "REDACTED"

# AWS Redshift
## Redshift's full DSN. Must follow pattern:
## 'postgresql://password:username@hostname:port/database'
PIPELINE_AWS_REDSHIFT_DSN = 'postgresql://REDACTED:REDACTED@REDACTED:5439/REDACTED'
## Target table's full path. Must follow pattern:
## schema_name.table_name
PIPELINE_AWS_REDSHIFT_TABLE = 'REDACTED'

# Google Sheet detail
## Google sheet ID
## Example:
## https://docs.google.com/spreadsheets/d/1CEopPJOmJLjbeqzTk0xo7mkMsXlLdqvcMkb6Jz1nUmI/edit#gid=0
## ID then is "1CEopPJOmJLjbeqzTk0xo7mkMsXlLdqvcMkb6Jz1nUmI"
PIPELINE_GOOGLE_SHEET_ID = "REDACTED"
## Contents of the downloaded service_accounts.json file.
## Contents must be placed in one line and newlines seperated with '\n' meta-character
PIPELINE_GOOGLE_SERVICE_ACCOUNT = '{"type":"service_account","project_id": ... "}'
